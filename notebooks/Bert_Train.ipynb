{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert_Train.ipynb","provenance":[{"file_id":"1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP","timestamp":1581258090238},{"file_id":"1dcucJvUOx6kdopjhVIwIdpby6VXhnvns","timestamp":1575478354980},{"file_id":"1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO","timestamp":1575307876986},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1556493831452}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-1fEfUvBfpgp","colab_type":"text"},"source":["This Notebook is for training the Bert model on classifying fraudulent job ads. It is used for 4 different parts of the ad: The description, benefits, requirements and the company profile. Depending on the part which it should be trained on, one has to adjust the cells accordingly (see comments in code)."]},{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej","colab_type":"text"},"source":["# 1. Preparation and Imports"]},{"cell_type":"markdown","metadata":{"id":"nSU7yERLP_66","colab_type":"text"},"source":["## 1.1. Using Colab GPU for Training\n"]},{"cell_type":"code","metadata":{"id":"DEfSbAA4QHas","colab_type":"code","outputId":"66ceb875-ab71-4c17-ae1f-df3524e30b66","executionInfo":{"status":"ok","timestamp":1582468623558,"user_tz":-60,"elapsed":4534,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cqG7FzRVFEIv","colab_type":"text"},"source":["In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "]},{"cell_type":"code","metadata":{"id":"oYsV4H8fCpZ-","colab_type":"code","outputId":"1e4072e5-9043-45d9-e7f2-ae0f3d873ec9","executionInfo":{"status":"ok","timestamp":1582468791884,"user_tz":-60,"elapsed":531,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2ElsnSNUridI","colab_type":"text"},"source":["## 1.2. Installing the Hugging Face Library\n"]},{"cell_type":"code","metadata":{"id":"0NmMdkZO8R6q","colab_type":"code","outputId":"6e7b12a6-3b52-4ff2-eb45-e5a16446a3fc","executionInfo":{"status":"ok","timestamp":1582468791889,"user_tz":-60,"elapsed":37,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":698}},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/58/3d789b98923da6485f376be1e04d59ad7003a63bdb2b04b5eea7e02857e5/transformers-2.5.0-py3-none-any.whl (481kB)\n","\r\u001b[K     |▊                               | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\r\u001b[K     |▍                               | 10kB 26.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 34.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 41.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 46.5MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 49.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 53.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 55.2MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 57.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 58.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 59.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 59.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 59.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 59.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 59.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 59.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 59.4MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 32kB/s \n","\u001b[?25hCollecting tokenizers==0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/1d/ea7e2c628942e686595736f73678348272120d026b7acd54fe43e5211bb1/tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 52.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=7fccdb68cb905ede8e0d9ad9814538d31fb7619c9c217e49f88d735355e6af2a\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.0 transformers-2.5.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wRqvWGa86mrA","colab_type":"text"},"source":["## 1.3. Mount drive in order to read files and later save model\n"]},{"cell_type":"code","metadata":{"id":"G1oSu-ElfW-I","colab_type":"code","outputId":"2575aae0-aa23-402f-ede9-372a01f7d1f8","executionInfo":{"status":"ok","timestamp":1582242306454,"user_tz":-60,"elapsed":10219,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IAHN6aMS8kdN","colab_type":"text"},"source":["# 2. Read in data and transform output to 1-0"]},{"cell_type":"code","metadata":{"id":"Wt9HZqF5fLn4","colab_type":"code","colab":{}},"source":["# Import train data \n","# change url accordingly\n","import pandas as pd\n","url='https://raw.githubusercontent.com/k-amini/NLP_RNN/master/clean_deduplicated_data/train_benefits.csv'\n","df = pd.read_csv(url)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gq5Tyncohcca","colab_type":"code","colab":{}},"source":["# get text blocks and corresponding labels\n","df.fraudulent = [0 if i=='f' else 1 for i in df.fraudulent ]\n","\n","# uncomment desired line\n","texts=df.benefits.values\n","#texts=df.company_profile.values\n","#texts=df.description.values\n","#texts=df.requirements.values\n","\n","text_labels=df.fraudulent.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-8kEDRvShcU5","colab_type":"text"},"source":["# 3. Tokenize with Bert Tokenizer\n","Fortunately, Bert comes with a pretrained tokenizer which can be used directly. "]},{"cell_type":"code","metadata":{"id":"Z474sSC6oe7A","colab_type":"code","outputId":"a3a269a8-5ab2-4d51-d276-5ff49ecc3fbd","executionInfo":{"status":"ok","timestamp":1582242306474,"user_tz":-60,"elapsed":10107,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","print('Done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n","Done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dFzmtleW6KmJ","colab_type":"text"},"source":["Let's apply the tokenizer to one sentence just to see the output.\n"]},{"cell_type":"code","metadata":{"id":"pFZKo2Qnk2Yd","colab_type":"code","outputId":"4b0f500b-7142-417c-c44b-9354f3f322ac","executionInfo":{"status":"ok","timestamp":1582242306477,"user_tz":-60,"elapsed":10085,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["\n","### and now for own data:\n","# Print the original sentence.\n","print('Now for job ads:')\n","print(' Original: ', texts[5])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(texts[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(texts[0])))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Now for job ads:\n"," Original:  nann\n","Tokenized:  ['nan', '##n']\n","Token IDs:  [16660, 2078]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NwfYE7Li92AN"},"source":["### Special Tokens\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"thH2LAEl92AB"},"source":["\n","**`[SEP]`**\n","\n","At the end of every sentence, we need to append the special `[SEP]` token. \n","\n","This token is an artifact of two-sentence tasks\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Hkvm1t5V91_p"},"source":["**`[CLS]`**\n","\n","For classification tasks, we must prepend the special `[CLS]` token to the begin\n"]},{"cell_type":"markdown","metadata":{"id":"u51v0kFxeteu","colab_type":"text"},"source":["### Sentence Length & Attention Mask\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qPNuwqZVK3T6","colab_type":"text"},"source":["The sentences in our dataset obviously have varying lengths. However, Bert has the following constraints:\n","\n","1. All sentences must be padded or truncated to a single, fixed length.\n","2. The maximum sentence length is 512 tokens.\n","\n","We will thus only use the first 512 words of each text and furthermore pad and tokenize.\n"]},{"cell_type":"markdown","metadata":{"id":"l6w8elb-58GJ","colab_type":"text"},"source":["## 3.2. Sentences to IDs"]},{"cell_type":"markdown","metadata":{"id":"1M296yz577fV","colab_type":"text"},"source":["The `tokenizer.encode` function combines multiple steps for us:\n","1. Split the sentence into tokens.\n","2. Add the special `[CLS]` and `[SEP]` tokens.\n","3. Map the tokens to their IDs.\n","\n","This function can perform truncating for us, but doesn't handle padding. "]},{"cell_type":"code","metadata":{"id":"J6RrzfYTc4cq","colab_type":"code","outputId":"8d03d9c6-1300-46f7-dec8-aacd9538af45","executionInfo":{"status":"ok","timestamp":1582242307303,"user_tz":-60,"elapsed":10884,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_own = []\n","\n","# For every sentence...\n","for i,sent in enumerate(texts):\n","  sent=str(sent)\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","  encoded_sent = tokenizer.encode(\n","      sent,                      # Sentence to encode.\n","      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","      max_length = 512       # Truncate all sentences.\n","      #return_tensors = 'pt'     # Return pytorch tensors.\n","      )\n","    \n","    # Add the encoded sentence to the list.\n","  input_ids_own.append(encoded_sent)\n","\n","# Print sentence 5, now as a list of IDs.\n","print('Original: ', texts[5])\n","print('Token IDs:', input_ids_own[5])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original:  nann\n","Token IDs: [101, 16660, 2078, 102]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WhwCKszh6ych","colab_type":"text"},"source":["## 3.3. Padding & Truncating"]},{"cell_type":"markdown","metadata":{"id":"xytsw1oIfnX0","colab_type":"text"},"source":["Pad and truncate our sequences so that they all have the same length, 512."]},{"cell_type":"code","metadata":{"id":"ZRATE80PlTHd","colab_type":"code","outputId":"c96166fe-8087-4448-96ac-b4fa140253b4","executionInfo":{"status":"ok","timestamp":1582242307310,"user_tz":-60,"elapsed":10849,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","MAX_LEN = 512\n","\n","print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","\n","print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","\n","# Pad our input tokens with value 0.\n","# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n","# as opposed to the beginning.\n","input_ids_own = pad_sequences(input_ids_own, maxlen=MAX_LEN, dtype=\"long\", \n","                          value=0, truncating=\"post\", padding=\"post\")\n","\n","print('\\nDone.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Padding/truncating all sentences to 512 values...\n","\n","Padding token: \"[PAD]\", ID: 0\n","\n","Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kDs-MYtYH8sL","colab_type":"text"},"source":["## 3.4. Attention Masks"]},{"cell_type":"markdown","metadata":{"id":"KhGulL1pExCT","colab_type":"text"},"source":["The attention mask simply makes it explicit which tokens are actual words versus which are padding. \n","\n","The BERT vocabulary does not use the ID 0, so if a token ID is 0, then it's padding, and otherwise it's a real token."]},{"cell_type":"code","metadata":{"id":"PLTO62y8lau4","colab_type":"code","colab":{}},"source":["# Create attention masks\n","attention_masks_own = []\n","\n","# For each sentence...\n","for sent in input_ids_own:\n","    \n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    \n","    # Store the attention mask for this sentence.\n","    attention_masks_own.append(att_mask)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCWfiv1Ilfm2","colab_type":"code","colab":{}},"source":["# rename inputs\n","train_inputs_own, train_labels_own = input_ids_own, text_labels\n","                                                 \n","train_masks_own = attention_masks_own\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7LzSbTqW9_BR","colab_type":"text"},"source":["\n","\n","## 3.5. Converting to PyTorch Data Types"]},{"cell_type":"markdown","metadata":{"id":"6p1uXczp-Je4","colab_type":"text"},"source":["Our model expects PyTorch tensors rather than numpy.ndarrays, so convert all of our dataset variables."]},{"cell_type":"code","metadata":{"id":"YzHpzUM-ljhc","colab_type":"code","colab":{}},"source":["\n","# Convert all inputs and labels into torch tensors, the required datatype \n","# for our model.\n","train_inputs_own = torch.tensor(train_inputs_own)\n","\n","train_labels_own = torch.tensor(train_labels_own)\n","\n","train_masks_own = torch.tensor(train_masks_own)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dD9i6Z2pG-sN","colab_type":"text"},"source":["We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."]},{"cell_type":"code","metadata":{"id":"XWDzLbd9loGT","colab_type":"code","colab":{}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# now for own data\n","batch_size = 4\n","\n","# Create the DataLoader for the training set.\n","train_data_own = TensorDataset(train_inputs_own, train_masks_own, train_labels_own)\n","train_sampler_own = RandomSampler(train_data_own)\n","train_dataloader_own = DataLoader(train_data_own, sampler=train_sampler_own, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8bwa6Rts-02-","colab_type":"text"},"source":["# 4. Train Our Classification Model"]},{"cell_type":"markdown","metadata":{"id":"3xYQ3iLO08SX","colab_type":"text"},"source":["Now that our input data is properly formatted, it's time to fine tune the BERT model. "]},{"cell_type":"markdown","metadata":{"id":"D6TKgyUzPIQc","colab_type":"text"},"source":["## 4.1. BertForSequenceClassification"]},{"cell_type":"markdown","metadata":{"id":"BXYitPoE-cjH","colab_type":"text"},"source":["\n","\n","We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"]},{"cell_type":"code","metadata":{"id":"gFsCTp_mporB","colab_type":"code","outputId":"0a0bfa94-dc22-4a82-dd44-efaaa9f1e9f1","executionInfo":{"status":"ok","timestamp":1582242310882,"user_tz":-60,"elapsed":14348,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Run on the GPU.\n","model.cuda()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"markdown","metadata":{"id":"e0Jv6c7-HHDW","colab_type":"text"},"source":["Just for curiosity's sake, we can browse all of the model's parameters by name here.\n","\n","In the below cell, I've printed out the names and dimensions of the weights for:\n","\n","1. The embedding layer.\n","2. The first of the twelve transformers.\n","3. The output layer.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"8PIiVlDYCtSq","colab_type":"code","outputId":"fb29c520-6afa-4ac8-de23-c3ca820dcd1c","executionInfo":{"status":"ok","timestamp":1582242310889,"user_tz":-60,"elapsed":14324,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":642}},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qRWT-D4U_Pvx","colab_type":"text"},"source":["## 4.2. Optimizer & Learning Rate Scheduler"]},{"cell_type":"markdown","metadata":{"id":"8o-VEBobKwHk","colab_type":"text"},"source":["Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n","\n","For the purposes of fine-tuning, the authors recommend choosing from the following values:\n","- Batch size: 16, 32  (We chose 4 because of memory issues)\n","- Learning rate (Adam): 5e-5, 3e-5, 2e-5  (We'll use 2e-5).\n","- Number of epochs: 2, 3, 4  \n","After some experiments, 5 epochs were found to perform best, so we choose 5.\n","\n"]},{"cell_type":"code","metadata":{"id":"GLs72DuMODJO","colab_type":"code","colab":{}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-p0upAhhRiIx","colab_type":"code","colab":{}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs \n","epochs = 5\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader_own) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RqfmWwUR_Sox","colab_type":"text"},"source":["## 4.3. Training Loop"]},{"cell_type":"code","metadata":{"id":"9cQNvaZ9bnyy","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KNhRtWPXH9C3","colab_type":"text"},"source":["Helper function for formatting elapsed times.\n"]},{"cell_type":"code","metadata":{"id":"gpt6tR83keZD","colab_type":"code","colab":{}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cfNIhN19te3N","colab_type":"text"},"source":["# Training!\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"6J-FYdx6nFE_","colab_type":"code","outputId":"96fa6edf-f7cd-4094-d290-27aac5b2768a","executionInfo":{"status":"ok","timestamp":1582243326637,"user_tz":-60,"elapsed":806392,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import random\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. \n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader_own):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader_own), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","        \n","        # The call to `model` always returns a tuple, so we need to pull the \n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader_own)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 5 ========\n","Training...\n","  Batch    40  of    375.    Elapsed: 0:00:21.\n","  Batch    80  of    375.    Elapsed: 0:00:43.\n","  Batch   120  of    375.    Elapsed: 0:01:05.\n","  Batch   160  of    375.    Elapsed: 0:01:26.\n","  Batch   200  of    375.    Elapsed: 0:01:48.\n","  Batch   240  of    375.    Elapsed: 0:02:09.\n","  Batch   280  of    375.    Elapsed: 0:02:31.\n","  Batch   320  of    375.    Elapsed: 0:02:53.\n","  Batch   360  of    375.    Elapsed: 0:03:15.\n","\n","  Average training loss: 0.60\n","  Training epoch took: 0:03:23\n","\n","======== Epoch 2 / 5 ========\n","Training...\n","  Batch    40  of    375.    Elapsed: 0:00:22.\n","  Batch    80  of    375.    Elapsed: 0:00:43.\n","  Batch   120  of    375.    Elapsed: 0:01:05.\n","  Batch   160  of    375.    Elapsed: 0:01:27.\n","  Batch   200  of    375.    Elapsed: 0:01:49.\n","  Batch   240  of    375.    Elapsed: 0:02:10.\n","  Batch   280  of    375.    Elapsed: 0:02:32.\n","  Batch   320  of    375.    Elapsed: 0:02:54.\n","  Batch   360  of    375.    Elapsed: 0:03:15.\n","\n","  Average training loss: 0.47\n","  Training epoch took: 0:03:23\n","\n","======== Epoch 3 / 5 ========\n","Training...\n","  Batch    40  of    375.    Elapsed: 0:00:22.\n","  Batch    80  of    375.    Elapsed: 0:00:43.\n","  Batch   120  of    375.    Elapsed: 0:01:05.\n","  Batch   160  of    375.    Elapsed: 0:01:27.\n","  Batch   200  of    375.    Elapsed: 0:01:48.\n","  Batch   240  of    375.    Elapsed: 0:02:10.\n","  Batch   280  of    375.    Elapsed: 0:02:32.\n","  Batch   320  of    375.    Elapsed: 0:02:53.\n","  Batch   360  of    375.    Elapsed: 0:03:15.\n","\n","  Average training loss: 0.37\n","  Training epoch took: 0:03:23\n","\n","======== Epoch 4 / 5 ========\n","Training...\n","  Batch    40  of    375.    Elapsed: 0:00:22.\n","  Batch    80  of    375.    Elapsed: 0:00:43.\n","  Batch   120  of    375.    Elapsed: 0:01:05.\n","  Batch   160  of    375.    Elapsed: 0:01:27.\n","  Batch   200  of    375.    Elapsed: 0:01:48.\n","  Batch   240  of    375.    Elapsed: 0:02:10.\n","  Batch   280  of    375.    Elapsed: 0:02:32.\n","  Batch   320  of    375.    Elapsed: 0:02:53.\n","  Batch   360  of    375.    Elapsed: 0:03:15.\n","\n","  Average training loss: 0.37\n","  Training epoch took: 0:03:23\n","\n","======== Epoch 5 / 5 ========\n","Training...\n","  Batch    40  of    375.    Elapsed: 0:00:22.\n","  Batch    80  of    375.    Elapsed: 0:00:43.\n","  Batch   120  of    375.    Elapsed: 0:01:05.\n","  Batch   160  of    375.    Elapsed: 0:01:27.\n","  Batch   200  of    375.    Elapsed: 0:01:48.\n","  Batch   240  of    375.    Elapsed: 0:02:10.\n","  Batch   280  of    375.    Elapsed: 0:02:32.\n","  Batch   320  of    375.    Elapsed: 0:02:53.\n","  Batch   360  of    375.    Elapsed: 0:03:15.\n","\n","  Average training loss: 0.35\n","  Training epoch took: 0:03:23\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1-G03mmwH3aI","colab_type":"text"},"source":["Let's take a look at our training loss over all batches:"]},{"cell_type":"code","metadata":{"id":"68xreA9JAmG5","colab_type":"code","outputId":"2053ae1f-b17d-4d11-e910-10a81ba891b4","executionInfo":{"status":"ok","timestamp":1582243326647,"user_tz":-60,"elapsed":133,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":427}},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(loss_values, 'b-o')\n","\n","# Label the plot.\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"q2079Qyn8Mt8","colab_type":"text"},"source":["# 6. Saving & Loading Fine-Tuned Model\n","\n","This cell (taken from `run_glue.py` [here](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) writes the model and tokenizer out to disk."]},{"cell_type":"code","metadata":{"id":"6ulTWaOr8QNY","colab_type":"code","outputId":"601c0096-f566-4e0e-faf0-01e5c0d439b3","executionInfo":{"status":"ok","timestamp":1582243327869,"user_tz":-60,"elapsed":1248,"user":{"displayName":"Maximilian Mueller","photoUrl":"","userId":"04765867508601940570"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["import os\n","\n","output_dir = './model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saving model to ./model_save/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('./model_save/vocab.txt',\n"," './model_save/special_tokens_map.json',\n"," './model_save/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"4mvyqDzXnEN-","colab_type":"code","colab":{}},"source":["# Copy model to google drive\n","# uncomment if desired and change path if necessary\n","#!cp -r ./model_save/ \"/content/drive/My Drive/Colab Notebooks/balanced_dup_removed/benefits\""],"execution_count":0,"outputs":[]}]}