{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_Evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ig92nsoUQg",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "This Notebook loads a pre-trained model from google drive and evaluates it on a previously generated test-set.\n",
        "Depending on which part of the job ad the model was trained on, the corresponding test set has to be chosen and some cells have to adjusted (see comments). The results will be presented in a separate notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEjzg6gprCR3",
        "colab_type": "text"
      },
      "source": [
        "# Preparation, Imports and Function definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBA-jpPPx6Vo",
        "colab_type": "code",
        "outputId": "4c0b6d08-4ddb-4bef-8536-747ed378ad14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.5.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD4z80Xbue-8",
        "colab_type": "code",
        "outputId": "cecaa4da-c236-4ee6-89be-a8ce879de46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# mount to drive\n",
        "# necessary for loading model, tokenizer and data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9GprtpZuqCo",
        "colab_type": "code",
        "outputId": "9dd38992-6b99-4954-da36-66d4abbfbd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "    \n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqhS7gTq1fot",
        "colab_type": "text"
      },
      "source": [
        "# Read in and clean data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKDTS_LVxWMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import test data \n",
        "import pandas as pd\n",
        "url='https://raw.githubusercontent.com/k-amini/NLP_RNN/master/study_data/study_description.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df.fraudulent = [0 if i=='f' else 1 for i in df.fraudulent ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmpe36DLBwAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['description']=df['description'].fillna('nann')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-A6jYIJrgYp",
        "colab_type": "text"
      },
      "source": [
        "The below cell was used to create a big df where all parts of the job ads are stored. You can ignore it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4QVX9vFQyMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # create big df\n",
        "# df_requirements=pd.read_csv('https://raw.githubusercontent.com/k-amini/NLP_RNN/master/clean_deduplicated_data/test_requirements.csv')\n",
        "# df_benefits=pd.read_csv('https://raw.githubusercontent.com/k-amini/NLP_RNN/master/clean_deduplicated_data/test_benefits.csv')\n",
        "# df_company_profile=pd.read_csv('https://raw.githubusercontent.com/k-amini/NLP_RNN/master/clean_deduplicated_data/test_company_profile.csv')\n",
        "#df_description=pd.read_csv('https://raw.githubusercontent.com/k-amini/NLP_RNN/master/clean_deduplicated_data/test_description.csv')\n",
        "\n",
        "# df_big = df_description.copy()\n",
        "# df_big['fraudulent']=[0 if i=='f' else 1 for i in df_big.fraudulent ]\n",
        "# df_big['company_profile']=df_company_profile.company_profile\n",
        "# df_big['requirements']=df_requirements.requirements\n",
        "# df_big['benefits']=df_benefits.benefits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHDynY0pzYV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get text blocks and corresponding labels\n",
        "texts=df.description.values\n",
        "text_labels=df.fraudulent.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sFwumsazlO5",
        "colab_type": "text"
      },
      "source": [
        "# Load Model and Tokenizer\n",
        "We will load the previously trained model from google drive. You can adjust the load_path accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj4VWlolzjqT",
        "colab_type": "code",
        "outputId": "84aea146-30ec-49c9-8fa4-64cc54abd5f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from transformers import *\n",
        "# Load a trained model and vocabulary \n",
        "load_path = \"/content/drive/My Drive/Colab Notebooks/balanced_dup_removed/description/model_save/\"\n",
        "# uncomment if unbalanced is desired\n",
        "#load_path = \"/content/drive/My Drive/Colab Notebooks/unbalanced/model_save/\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(load_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(load_path)\n",
        "# Copy the model to the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuVBqtyY1mx4",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize\n",
        "We have to prepare (tokenize etc.) the test set the same way as the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxfVe3T1wF4N",
        "colab_type": "code",
        "outputId": "f9738f35-9b26-41dd-b406-5f6976cadaed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids_own = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in texts:\n",
        "  #print(sent)\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "  encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        max_length = 512,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "  input_ids_own.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', texts[0])\n",
        "print('Token IDs:', input_ids_own[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  the group has raised a fund for the purchase of homes in the southeast. the student on this project will help them build their investments from the ground up and will help with the analysis and modeling of their investments. we should be looking for someone with a strong general finance skills and has a lot of entrepreneurial ability.\n",
            "Token IDs: [101, 1996, 2177, 2038, 2992, 1037, 4636, 2005, 1996, 5309, 1997, 5014, 1999, 1996, 4643, 1012, 1996, 3076, 2006, 2023, 2622, 2097, 2393, 2068, 3857, 2037, 10518, 2013, 1996, 2598, 2039, 1998, 2097, 2393, 2007, 1996, 4106, 1998, 11643, 1997, 2037, 10518, 1012, 2057, 2323, 2022, 2559, 2005, 2619, 2007, 1037, 2844, 2236, 5446, 4813, 1998, 2038, 1037, 2843, 1997, 10670, 4818, 3754, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDKAkl5D1psZ",
        "colab_type": "text"
      },
      "source": [
        "# Pad (important: Use same padding as used in training - 512)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jinu5d7qwJcE",
        "colab_type": "code",
        "outputId": "dc79cbf8-4de5-4319-f9ce-b50147f12b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Now for own data\n",
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 512\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids_own = pad_sequences(input_ids_own, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 512 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HAairVf1weW",
        "colab_type": "text"
      },
      "source": [
        "# Create attention masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJfStB5-wLnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks_own = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids_own:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks_own.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmI1X8Tm10cU",
        "colab_type": "text"
      },
      "source": [
        "# Convert everything to correct datatypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62qT1CmIwUeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "\n",
        "input_ids = torch.tensor(input_ids_own)\n",
        "labels = torch.tensor(text_labels)\n",
        "masks = torch.tensor(attention_masks_own)\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# now for own data\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "data_ = TensorDataset(input_ids, masks, labels)\n",
        "sampler_ = SequentialSampler(data_)\n",
        "dataloader_ = DataLoader(data_, sampler=sampler_, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d69D8Szg151d",
        "colab_type": "text"
      },
      "source": [
        "# Helper functions for accuracy evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4evMf9yFwdHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# recalculating probabilities from logits for one batch\n",
        "import math\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "def get_proba_batch(batch):\n",
        "  return [sigmoid(logits[i][1])/(sigmoid(logits[i][0])+sigmoid(logits[i][1])) for i in range(len(batch))]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcQyeZV919Mm",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate model and create new column in df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJz_2V0RwkER",
        "colab_type": "code",
        "outputId": "5c7acc7a-cb1e-4f0e-fa1c-4de64167fbe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "preds_all=[]\n",
        "probas_all=[]\n",
        "# Evaluate data for one epoch\n",
        "for batch in dataloader_:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have\n",
        "        # not provided labels.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "    # values prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    preds_all += np.argmax(logits,axis=1).tolist()\n",
        "    probas_all += get_proba_batch(logits)\n",
        "    # Calculate the accuracy for this batch of test sentences.\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    # Accumulate the total accuracy.\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    # Track the number of batches\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "# ad predictions to dataframe\n",
        "df['preds']=np.array(preds_all)\n",
        "df['pred_proba']=np.array(probas_all)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmfeYGhhN9Mx",
        "colab_type": "code",
        "outputId": "f3cc15a3-1fe2-48df-d740-c5b40d108f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fraudulent</th>\n",
              "      <th>description</th>\n",
              "      <th>preds</th>\n",
              "      <th>pred_proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>the group has raised a fund for the purchase o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.309939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>sales executive</td>\n",
              "      <td>1</td>\n",
              "      <td>0.958895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>a newly established company seeks outgoing, fr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.984503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>administrative assistantessential job responsi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.982772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>normal 0 false false false en-us x-none x-none...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.021576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fraudulent  ... pred_proba\n",
              "0           1  ...   0.309939\n",
              "1           1  ...   0.958895\n",
              "2           1  ...   0.984503\n",
              "3           1  ...   0.982772\n",
              "4           0  ...   0.021576\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbRUchpJsWIv",
        "colab_type": "text"
      },
      "source": [
        "# Save output \n",
        "Save output as csv and copy it to google drive. Uncomment if desired"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzLmvAGSIWaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_big.to_csv('Bert_balanced_nodupl_5epochs_test_preds.csv')\n",
        "# !cp  ./Bert_balanced_nodupl_5epochs_test_preds.csv \"/content/drive/My Drive/Colab Notebooks/balanced_dup_removed/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVkUZuR3smXS",
        "colab_type": "text"
      },
      "source": [
        "# Create confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iez8NYIFX_ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "def plot_confusion_matrix(cm, class_labels):\n",
        "    \"\"\"Pretty prints a confusion matrix as a figure\n",
        "\n",
        "    Args:\n",
        "        cm:  A confusion matrix for example\n",
        "        [[245, 5 ], \n",
        "         [ 34, 245]]\n",
        "         \n",
        "        class_labels: The list of class labels to be plotted on x-y axis\n",
        "\n",
        "    Rerturns:\n",
        "        Just plots the confusion matrix.\n",
        "    \"\"\"\n",
        "    \n",
        "    df_cm = pd.DataFrame(cm, index = [i for i in class_labels],\n",
        "                  columns = [i for i in class_labels])\n",
        "    sns.set(font_scale=1)\n",
        "    sns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted label\")\n",
        "    plt.ylabel(\"Real label\")\n",
        "    plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "def get_auc(y, y_pred_probabilities, class_labels, column =1, plot = True):\n",
        "    \"\"\"Plots ROC AUC\n",
        "    \"\"\"\n",
        "    fpr, tpr, _ = roc_curve(y == column, y_pred_probabilities[:,column],drop_intermediate = False)\n",
        "    roc_auc = roc_auc_score(y_true=y, y_score=y_pred_probabilities[:,1])\n",
        "    print (\"AUC: \", roc_auc)\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.0])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IusTWMcGcBaD",
        "colab_type": "code",
        "outputId": "060a9605-1f9f-4f1e-8045-875cd6b3bb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(df.fraudulent,df.preds)\n",
        "plot_confusion_matrix(cm,class_labels=['no fraud','fraud'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEMCAYAAADOLq1xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE1v3y9RG-kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}